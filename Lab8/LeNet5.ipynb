{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDbJWoO1yO8e"
   },
   "source": [
    "# Image Classification with CNN - LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzQxqD6HyO8i"
   },
   "source": [
    "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFyVotRvyO8j"
   },
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTHLyL1fyO8j",
    "outputId": "19e29ee8-1f18-447b-a6b2-9ae79effb408",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# # # If your computer is slow, try to use a subset of data, e.g.\n",
    "# X_train = X_train[:10000]\n",
    "# y_train = y_train[:10000]\n",
    "# X_test = X_test[:2000]\n",
    "# y_test = y_test[:2000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8ShXIANyO8l"
   },
   "source": [
    "As you already know, this dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BvNG0PbyO8l"
   },
   "source": [
    "You can have a look at some images if needed, even if you already know them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "lnjqgv-GyO8m",
    "outputId": "3666f0d8-de2c-4709-b746-b1cf0c459f53",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "\n",
    "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
    "plt.title(label_class[y_train[idx]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdYH6XW1yO8n"
   },
   "source": [
    "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fjv8XMPByO8o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Make the data preparation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=10)\n",
    "y_test_cat = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "X_train_norm = X_train/255\n",
    "X_test_norm = X_test/255\n",
    "\n",
    "\n",
    "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0],28,28,1)\n",
    "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0],28,28,1)\n",
    "\n",
    "X_train_norm.shape #Should be (60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9LKzxR9yO8o"
   },
   "source": [
    "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
    "\n",
    "The architecture is the following:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GKyMFlL6yO8o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
      "                                                                 \n",
      " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " C5 (Dense)                  (None, 120)               48120     \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                10164     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build your model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def lenet5():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Layer C1\n",
    "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "    # Layer S2\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
    "    # Layer C3\n",
    "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
    "    # Layer S4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
    "    # Before going into layer C5, we flatten our units\n",
    "    model.add(Flatten())\n",
    "    # Layer C5\n",
    "    model.add(Dense(units=120, activation = 'relu', name = 'C5'))\n",
    "    # Layer F6\n",
    "    model.add(Dense(units=84, activation = 'relu', name = 'F6'))\n",
    "    # Output layer\n",
    "    model.add(Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "lenet5().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1qBEauqyO8p"
   },
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPL3aKnyyO8p",
    "outputId": "9157f4ba-7840-4080-ecf9-7826ebca3f94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 5s 155ms/step - loss: 1.4933 - accuracy: 0.5484 - val_loss: 0.8386 - val_accuracy: 0.6926\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 4s 136ms/step - loss: 0.7155 - accuracy: 0.7328 - val_loss: 0.6511 - val_accuracy: 0.7532\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 4s 127ms/step - loss: 0.5987 - accuracy: 0.7740 - val_loss: 0.5851 - val_accuracy: 0.7793\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.5452 - accuracy: 0.7956 - val_loss: 0.5432 - val_accuracy: 0.7984\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.5060 - accuracy: 0.8141 - val_loss: 0.5221 - val_accuracy: 0.8012\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.4788 - accuracy: 0.8265 - val_loss: 0.5044 - val_accuracy: 0.8168\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.4613 - accuracy: 0.8335 - val_loss: 0.4925 - val_accuracy: 0.8189\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.4461 - accuracy: 0.8401 - val_loss: 0.4611 - val_accuracy: 0.8359\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.4301 - accuracy: 0.8465 - val_loss: 0.4532 - val_accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.4222 - accuracy: 0.8497 - val_loss: 0.4489 - val_accuracy: 0.8382\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.4145 - accuracy: 0.8511 - val_loss: 0.4362 - val_accuracy: 0.8470\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.4051 - accuracy: 0.8557 - val_loss: 0.4377 - val_accuracy: 0.8431\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3991 - accuracy: 0.8569 - val_loss: 0.4231 - val_accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3868 - accuracy: 0.8632 - val_loss: 0.4063 - val_accuracy: 0.8592\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3771 - accuracy: 0.8667 - val_loss: 0.4032 - val_accuracy: 0.8601\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3713 - accuracy: 0.8683 - val_loss: 0.4012 - val_accuracy: 0.8584\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3682 - accuracy: 0.8681 - val_loss: 0.3921 - val_accuracy: 0.8604\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3611 - accuracy: 0.8720 - val_loss: 0.3878 - val_accuracy: 0.8641\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.3598 - accuracy: 0.8714 - val_loss: 0.3790 - val_accuracy: 0.8670\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3510 - accuracy: 0.8745 - val_loss: 0.3784 - val_accuracy: 0.8656\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3466 - accuracy: 0.8753 - val_loss: 0.3709 - val_accuracy: 0.8693\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3461 - accuracy: 0.8763 - val_loss: 0.3722 - val_accuracy: 0.8673\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.3390 - accuracy: 0.8778 - val_loss: 0.3651 - val_accuracy: 0.8707\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.3327 - accuracy: 0.8809 - val_loss: 0.3617 - val_accuracy: 0.8690\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3284 - accuracy: 0.8832 - val_loss: 0.3689 - val_accuracy: 0.8690\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.3304 - accuracy: 0.8815 - val_loss: 0.3580 - val_accuracy: 0.8706\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3270 - accuracy: 0.8832 - val_loss: 0.3622 - val_accuracy: 0.8727\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.3217 - accuracy: 0.8850 - val_loss: 0.3569 - val_accuracy: 0.8751\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3170 - accuracy: 0.8866 - val_loss: 0.3582 - val_accuracy: 0.8707\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.3157 - accuracy: 0.8863 - val_loss: 0.3417 - val_accuracy: 0.8779\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3093 - accuracy: 0.8887 - val_loss: 0.3494 - val_accuracy: 0.8747\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3082 - accuracy: 0.8891 - val_loss: 0.3439 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.3043 - accuracy: 0.8906 - val_loss: 0.3402 - val_accuracy: 0.8780\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.3064 - accuracy: 0.8896 - val_loss: 0.3467 - val_accuracy: 0.8758\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.3030 - accuracy: 0.8906 - val_loss: 0.3353 - val_accuracy: 0.8773\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2945 - accuracy: 0.8951 - val_loss: 0.3292 - val_accuracy: 0.8827\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2918 - accuracy: 0.8953 - val_loss: 0.3367 - val_accuracy: 0.8801\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2904 - accuracy: 0.8967 - val_loss: 0.3319 - val_accuracy: 0.8804\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2920 - accuracy: 0.8953 - val_loss: 0.3246 - val_accuracy: 0.8833\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2864 - accuracy: 0.8972 - val_loss: 0.3381 - val_accuracy: 0.8761\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2899 - accuracy: 0.8953 - val_loss: 0.3396 - val_accuracy: 0.8785\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2853 - accuracy: 0.8968 - val_loss: 0.3228 - val_accuracy: 0.8843\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2782 - accuracy: 0.8998 - val_loss: 0.3191 - val_accuracy: 0.8841\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2771 - accuracy: 0.9001 - val_loss: 0.3240 - val_accuracy: 0.8830\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2814 - accuracy: 0.8979 - val_loss: 0.3398 - val_accuracy: 0.8755\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2788 - accuracy: 0.9002 - val_loss: 0.3259 - val_accuracy: 0.8812\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2743 - accuracy: 0.9004 - val_loss: 0.3189 - val_accuracy: 0.8844\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2716 - accuracy: 0.9019 - val_loss: 0.3234 - val_accuracy: 0.8819\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2693 - accuracy: 0.9028 - val_loss: 0.3336 - val_accuracy: 0.8772\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.2701 - accuracy: 0.9022 - val_loss: 0.3173 - val_accuracy: 0.8868\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 4s 132ms/step - loss: 0.2634 - accuracy: 0.9050 - val_loss: 0.3144 - val_accuracy: 0.8878\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 4s 131ms/step - loss: 0.2621 - accuracy: 0.9063 - val_loss: 0.3143 - val_accuracy: 0.8874\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2638 - accuracy: 0.9043 - val_loss: 0.3277 - val_accuracy: 0.8835\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2633 - accuracy: 0.9044 - val_loss: 0.3145 - val_accuracy: 0.8873\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2577 - accuracy: 0.9059 - val_loss: 0.3128 - val_accuracy: 0.8883\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2586 - accuracy: 0.9068 - val_loss: 0.3169 - val_accuracy: 0.8890\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2561 - accuracy: 0.9061 - val_loss: 0.3147 - val_accuracy: 0.8864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2572 - accuracy: 0.9061 - val_loss: 0.3096 - val_accuracy: 0.8900\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2504 - accuracy: 0.9092 - val_loss: 0.3140 - val_accuracy: 0.8897\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2513 - accuracy: 0.9089 - val_loss: 0.3108 - val_accuracy: 0.8882\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2493 - accuracy: 0.9097 - val_loss: 0.3062 - val_accuracy: 0.8911\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2446 - accuracy: 0.9115 - val_loss: 0.3119 - val_accuracy: 0.8880\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2432 - accuracy: 0.9120 - val_loss: 0.3106 - val_accuracy: 0.8886\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2552 - accuracy: 0.9067 - val_loss: 0.3163 - val_accuracy: 0.8871\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2428 - accuracy: 0.9120 - val_loss: 0.3077 - val_accuracy: 0.8897\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2405 - accuracy: 0.9135 - val_loss: 0.3095 - val_accuracy: 0.8890\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2411 - accuracy: 0.9132 - val_loss: 0.3073 - val_accuracy: 0.8888\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2366 - accuracy: 0.9144 - val_loss: 0.3133 - val_accuracy: 0.8881\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2377 - accuracy: 0.9144 - val_loss: 0.3049 - val_accuracy: 0.8908\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2359 - accuracy: 0.9147 - val_loss: 0.3055 - val_accuracy: 0.8926\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2367 - accuracy: 0.9135 - val_loss: 0.3164 - val_accuracy: 0.8870\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2325 - accuracy: 0.9162 - val_loss: 0.3032 - val_accuracy: 0.8907\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2306 - accuracy: 0.9157 - val_loss: 0.3001 - val_accuracy: 0.8936\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2287 - accuracy: 0.9176 - val_loss: 0.3014 - val_accuracy: 0.8955\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2290 - accuracy: 0.9162 - val_loss: 0.3052 - val_accuracy: 0.8908\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2266 - accuracy: 0.9172 - val_loss: 0.2999 - val_accuracy: 0.8923\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2282 - accuracy: 0.9171 - val_loss: 0.2990 - val_accuracy: 0.8941\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2233 - accuracy: 0.9194 - val_loss: 0.3018 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2227 - accuracy: 0.9196 - val_loss: 0.3042 - val_accuracy: 0.8909\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.2199 - accuracy: 0.9207 - val_loss: 0.3034 - val_accuracy: 0.8944\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2198 - accuracy: 0.9202 - val_loss: 0.3056 - val_accuracy: 0.8914\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2207 - accuracy: 0.9195 - val_loss: 0.3099 - val_accuracy: 0.8899\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 4s 127ms/step - loss: 0.2213 - accuracy: 0.9194 - val_loss: 0.2991 - val_accuracy: 0.8914\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 4s 128ms/step - loss: 0.2160 - accuracy: 0.9215 - val_loss: 0.2995 - val_accuracy: 0.8922\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 4s 127ms/step - loss: 0.2166 - accuracy: 0.9215 - val_loss: 0.2980 - val_accuracy: 0.8966\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 4s 137ms/step - loss: 0.2171 - accuracy: 0.9210 - val_loss: 0.3074 - val_accuracy: 0.8908\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 4s 126ms/step - loss: 0.2124 - accuracy: 0.9234 - val_loss: 0.2977 - val_accuracy: 0.8943\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.2103 - accuracy: 0.9242 - val_loss: 0.3088 - val_accuracy: 0.8937\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 4s 125ms/step - loss: 0.2130 - accuracy: 0.9227 - val_loss: 0.3012 - val_accuracy: 0.8928\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2099 - accuracy: 0.9240 - val_loss: 0.2967 - val_accuracy: 0.8918\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2074 - accuracy: 0.9250 - val_loss: 0.3038 - val_accuracy: 0.8915\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2058 - accuracy: 0.9249 - val_loss: 0.2958 - val_accuracy: 0.8952\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2068 - accuracy: 0.9248 - val_loss: 0.3036 - val_accuracy: 0.8908\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2133 - accuracy: 0.9225 - val_loss: 0.2973 - val_accuracy: 0.8943\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2036 - accuracy: 0.9261 - val_loss: 0.3009 - val_accuracy: 0.8930\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2035 - accuracy: 0.9251 - val_loss: 0.3268 - val_accuracy: 0.8820\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2070 - accuracy: 0.9240 - val_loss: 0.3113 - val_accuracy: 0.8905\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2057 - accuracy: 0.9245 - val_loss: 0.2974 - val_accuracy: 0.8970\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 4s 123ms/step - loss: 0.2010 - accuracy: 0.9272 - val_loss: 0.2993 - val_accuracy: 0.8947\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 4s 122ms/step - loss: 0.2015 - accuracy: 0.9268 - val_loss: 0.2935 - val_accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b06af8cb20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Compile and fit your model\n",
    "import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "model = lenet5()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define now our callbacks\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "\n",
    "# Finally fit the model\n",
    "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf-SqjjOyO8q"
   },
   "source": [
    "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2FTj7TSyO8q"
   },
   "source": [
    "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPjJoMQZyO8q",
    "outputId": "208f6295-df11-4146-8eeb-e81f1c4322d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 0.93075\n",
      "accuracy on test with NN: 0.8956\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vulsgHiyO8q"
   },
   "source": [
    "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
    "\n",
    "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
    "* `horizontal_flip=True`\n",
    "\n",
    "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
    "\n",
    "Begin by creating an object `ImageDataGenerator` with this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T11:58:37.442182Z",
     "start_time": "2020-08-19T11:58:37.438397Z"
    },
    "id": "pas-fMSIyO8q"
   },
   "outputs": [],
   "source": [
    "# TODO: Instantiate an ImageDataGenerator object\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7nCnu9syO8r"
   },
   "source": [
    "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zt6wXa3IyO8r",
    "outputId": "aa6078bb-d14e-4c98-97d0-49cdec4785f2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/58 [..............................] - ETA: 4s - loss: 0.2333 - accuracy: 0.9170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darks\\AppData\\Local\\Temp/ipykernel_3996/3271627435.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 5s 82ms/step - loss: 0.2129 - accuracy: 0.9229 - val_loss: 0.2827 - val_accuracy: 0.9009\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 0.2149 - accuracy: 0.9226 - val_loss: 0.3002 - val_accuracy: 0.8963\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.2140 - accuracy: 0.9220 - val_loss: 0.2852 - val_accuracy: 0.8980\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.2125 - accuracy: 0.9230 - val_loss: 0.2811 - val_accuracy: 0.8999\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.2092 - accuracy: 0.9226 - val_loss: 0.2823 - val_accuracy: 0.9034\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 0.2067 - accuracy: 0.9245 - val_loss: 0.2851 - val_accuracy: 0.8994\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 0.2080 - accuracy: 0.9240 - val_loss: 0.2917 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 5s 87ms/step - loss: 0.2075 - accuracy: 0.9232 - val_loss: 0.2845 - val_accuracy: 0.9019\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.2041 - accuracy: 0.9252 - val_loss: 0.2880 - val_accuracy: 0.9006\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 0.2062 - accuracy: 0.9240 - val_loss: 0.2857 - val_accuracy: 0.9004\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 5s 86ms/step - loss: 0.2015 - accuracy: 0.9263 - val_loss: 0.2849 - val_accuracy: 0.8980\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 0.2019 - accuracy: 0.9255 - val_loss: 0.3060 - val_accuracy: 0.8970\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.1992 - accuracy: 0.9270 - val_loss: 0.2792 - val_accuracy: 0.9043\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 0.1984 - accuracy: 0.9273 - val_loss: 0.2935 - val_accuracy: 0.8985\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 0.1958 - accuracy: 0.9277 - val_loss: 0.2903 - val_accuracy: 0.8997\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 0.1922 - accuracy: 0.9299 - val_loss: 0.2827 - val_accuracy: 0.9029\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 0.1907 - accuracy: 0.9297 - val_loss: 0.2997 - val_accuracy: 0.9014\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 0.1924 - accuracy: 0.9293 - val_loss: 0.3104 - val_accuracy: 0.8919\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 0.1928 - accuracy: 0.9290 - val_loss: 0.2889 - val_accuracy: 0.8993\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 5s 86ms/step - loss: 0.1889 - accuracy: 0.9304 - val_loss: 0.2886 - val_accuracy: 0.8993\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.1922 - accuracy: 0.9300 - val_loss: 0.2861 - val_accuracy: 0.9015\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 0.1890 - accuracy: 0.9307 - val_loss: 0.2912 - val_accuracy: 0.8982\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 0.1835 - accuracy: 0.9329 - val_loss: 0.2870 - val_accuracy: 0.9034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b009f7c5e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: train your model\n",
    "batch_size = 1024\n",
    "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
    "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
    "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuzFke8pyO8r"
   },
   "source": [
    "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jsTm86tuyO8r",
    "outputId": "36b5c6a1-63b6-4a92-82ea-961422411014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train with NN: 0.9380666666666667\n",
      "accuracy on test with NN: 0.9034\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the accuracy of your model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size=1024\n",
    "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
    "\n",
    "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
    "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOzkdGf7yO8s"
   },
   "source": [
    "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "01-LeNet5-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
